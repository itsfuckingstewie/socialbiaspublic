The study has revealed many types of swear words; namely epithet, profanity, obscenity, cursing, blasphemy, taboo, vulgarity or the use of substandard vulgar terms, slang, insults, scatology, semantic derogation, ethnic/racial/ gender slurs, animal names mentioning, ancestral allusions, and propositional and so on.  \\


Swear/taboo words are both noticeable to audiences and associated with social attitudes and judgments, including language ideologies. They are also subject to regulations. At the same time, they have important functions for the narrative. \\ https://www.sciencedirect.com/science/article/pii/S2211695818302976 \\

All the words have different layers and well try to predict to what degree a specific word is insulting. 
 
In mathematics and statistical analyses, human opinion is usually portrayed with discrete or continuous variables.\\
In both cases, these real-valued modelling choices of opinion are assumed to be clear and precise. However, it is obvious that human perception is often involved by uncertainty and subjectivity. Conventional statistical methods appear to be limited in terms of capturing this uncertainty and describing it in a precise manner. \\Despite the fact that exact modelling methods are widely used, vagueness in human responses cannot be avoided, especially when it comes to a verbal language. By verbal language, we mean the inherent semantics that a human would use to describe a given phenomenon, such as “approximately”, “around”, or “between good and bad”. Much like traditional surveys, practitioners tend to use the categorical variables for which the modalities are often given by Likert scales. \\
For instance, the concept of linguistic questionnaires arise. This type of questionnaires is defined as a set of items, i.e., the questions that are encoded by the given categories. The modalities are then called “linguistics”. \\
Linguistic questionnaires are used in a wide number of fields, such as in satisfaction surveys, economic sciences, and so forth. Getting exact answers from such questionnaires is, in some sense, impossible. It may be because of the limited amount of linguistics per question. These questionnaires are thus strongly affected by imprecision.\\


In our academic research, we have defined the conditions and applied a computational approach, publicopinion measurements, proofs, and applications. 

1. 𝘞𝘦 𝘦𝘴𝘵𝘪𝘮𝘢𝘵𝘦𝘥 𝘵𝘩𝘦 𝘥𝘦𝘮𝘰𝘵𝘪𝘰𝘯 𝘰𝘧 𝘰𝘯𝘭𝘪𝘯𝘦 𝘱𝘰𝘴𝘵𝘴 𝘢𝘯𝘥 𝘴𝘦𝘢𝘳𝘤𝘩 𝘳𝘦𝘴𝘶𝘭𝘵𝘴 𝘣𝘺 𝘤𝘳𝘰𝘴𝘴-𝘳𝘦𝘧𝘦𝘳𝘦𝘯𝘤𝘪𝘯𝘨 𝘢 𝘨𝘦𝘯𝘦𝘳𝘢𝘭 𝘌𝘯𝘨𝘭𝘪𝘴𝘩 𝘭𝘢𝘯𝘨𝘶𝘢𝘨𝘦 𝘤𝘰𝘳𝘱𝘶𝘴. 𝘋𝘦𝘳𝘪𝘷𝘢𝘵𝘪𝘰𝘯 𝘧𝘳𝘰𝘮 𝘵𝘩𝘦𝘴𝘦 𝘧𝘪𝘯𝘥𝘪𝘯𝘨𝘴 𝘢𝘱𝘱𝘭𝘪𝘦𝘴 𝘵𝘰 𝘥𝘪𝘧𝘧𝘦𝘳𝘦𝘯𝘵 𝘭𝘦𝘷𝘦𝘭𝘴 𝘢𝘯𝘥 𝘴𝘦𝘯𝘵𝘪𝘮𝘦𝘯𝘵𝘴 𝘰𝘧 censorship 𝘰𝘯 𝘥𝘪𝘷𝘦𝘳𝘨𝘦𝘯𝘵 𝘱𝘭𝘢𝘵𝘧𝘰𝘳𝘮𝘴 / 𝘴𝘦𝘢𝘳𝘤𝘩𝘦𝘯𝘨𝘪𝘯𝘦𝘴 (google , safari , facebook , twitter , and others) 

2. 𝘞𝘦 𝘩𝘢𝘷𝘦 𝘤𝘳𝘦𝘢𝘵𝘦𝘥 𝘢 𝘱𝘳𝘰𝘨𝘳𝘢𝘮 𝘧𝘰𝘳 𝘤𝘦𝘯𝘴𝘰𝘳𝘴𝘩𝘪𝘱 𝘥𝘦𝘵𝘦𝘤𝘵𝘪𝘰𝘯, 𝘱𝘭𝘢𝘵𝘧𝘰𝘳𝘮 𝘦𝘴𝘵𝘪𝘮𝘢𝘵𝘪𝘰𝘯 𝘰𝘧 𝘴𝘰𝘤𝘪𝘢𝘭 𝘣𝘪𝘢𝘴𝘦𝘴 𝘰𝘳 𝘤𝘰𝘯𝘴𝘵𝘳𝘢𝘪𝘯𝘵𝘴, 𝘢𝘯𝘥 𝘥𝘦𝘳𝘪𝘷𝘢𝘵𝘪𝘰𝘯 𝘰𝘧 𝘶𝘴𝘦𝘳𝘴/𝘱𝘭𝘢𝘵𝘧𝘰𝘳𝘮𝘴' 𝘳𝘦𝘴𝘱𝘰𝘯𝘴𝘪𝘣𝘪𝘭𝘪𝘵𝘺 𝘪𝘯 #𝘧𝘳𝘦𝘦𝘴𝘱𝘦𝘦𝘤𝘩 𝘱𝘰𝘴𝘵𝘴/𝘮𝘦𝘴𝘴𝘢𝘨𝘦𝘴. 

3. 𝘈𝘵 𝘭𝘢𝘴𝘵, 𝘸𝘦 𝘸𝘦𝘳𝘦 𝘵𝘳𝘺𝘪𝘯𝘨 𝘵𝘰 𝘧𝘪𝘨𝘶𝘳𝘦 𝘰𝘶𝘵 𝘵𝘰 𝘸𝘩𝘢𝘵 𝘦𝘹𝘵𝘦𝘯𝘵 𝘪𝘴 𝘵𝘩𝘪𝘴 𝘵𝘩𝘦 𝘤𝘰𝘮𝘱𝘢𝘯𝘺'𝘴, 𝘵𝘩𝘦 𝘶𝘴𝘦𝘳'𝘴, 𝘢𝘯𝘥 𝘴𝘵𝘢𝘵𝘦 𝘭𝘦𝘨𝘪𝘴𝘭𝘢𝘵𝘰𝘳𝘴' #𝘳𝘦𝘴𝘱𝘰𝘯𝘴𝘪𝘣𝘪𝘭𝘪𝘵𝘺. 𝘞𝘦 𝘩𝘢𝘷𝘦 𝘴𝘦𝘦𝘯 𝘵𝘩𝘦 𝘵𝘸𝘦𝘦𝘵 𝘵𝘩𝘢𝘵 𝘵𝘩𝘦 𝘯𝘦𝘸 𝘱𝘰𝘭𝘪𝘤𝘺 𝘪𝘴 #𝘧𝘳𝘦𝘦𝘥𝘰𝘮𝘰𝘧𝘴𝘱𝘦𝘦𝘤𝘩, 𝘣𝘶𝘵 𝘯𝘰𝘵 #𝘧𝘳𝘦𝘦𝘥𝘰𝘮𝘰𝘧𝘳𝘦𝘢𝘤𝘩. 𝘞𝘦 𝘩𝘢𝘷𝘦 𝘴𝘦𝘦𝘯 𝘵𝘩𝘢𝘵 𝘯𝘦𝘨𝘢𝘵𝘪𝘷𝘦/𝘩𝘢𝘵𝘦 #tweets 𝘸𝘪𝘭𝘭 𝘣𝘦 𝘮𝘢𝘹 𝘥𝘦𝘣𝘰𝘰𝘴𝘵𝘦𝘥 𝘢𝘯𝘥 𝘥𝘦𝘮𝘰𝘯𝘦𝘵𝘪𝘻𝘦𝘥. 
